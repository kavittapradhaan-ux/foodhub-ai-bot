{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNPH2cqT8z9TPbYmzRFuBOY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavittapradhaan-ux/foodhub-ai-bot/blob/main/foodhub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1.1 System & AI Library Installation ---\n",
        "# Optimized for the T4 GPU in Google Colab\n",
        "!pip install -q --no-deps \\\n",
        "    \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" \\\n",
        "    bitsandbytes==0.48.1 \\\n",
        "    accelerate==1.10.1 \\\n",
        "    xformers==0.0.33.post2 \\\n",
        "    peft==0.17.1 \\\n",
        "    trl==0.24.0 \\\n",
        "    cut-cross-entropy==25.1.1 \\\n",
        "    sentencepiece==0.2.1 \\\n",
        "    protobuf==5.29.5\n",
        "\n",
        "# --- 1.2 LangChain & Utility Installation ---\n",
        "!pip uninstall -y langchain\n",
        "!pip install -qU langchain langchain-community langchain-google-genai sqlalchemy transformers\n",
        "\n",
        "import os\n",
        "import sqlite3\n",
        "import torch\n",
        "import urllib\n",
        "from google.colab import files\n",
        "from unsloth import FastLanguageModel\n",
        "from langchain_core.language_models.llms import LLM\n",
        "from typing import Optional, List, Any\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain_community.agent_toolkits import create_sql_agent\n",
        "# Removed: from langchain import hub # This import is causing an error\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "# Setup API Key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBOqnkwxCuHwsQwFiTVSD9mu31V50TnURA\"\n",
        "\n",
        "print(\"âœ… Installation and Environment Setup Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziuRYnV5Mpkl",
        "outputId": "2fdd1f0d-1ae6-49df-e4fd-8d6300e5d6c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Found existing installation: langchain 1.2.6\n",
            "Uninstalling langchain-1.2.6:\n",
            "  Successfully uninstalled langchain-1.2.6\n",
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "âœ… Installation and Environment Setup Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2.1 Database Creation/Upload ---\n",
        "def setup_database():\n",
        "    if not os.path.exists(\"customer_orders.db\"):\n",
        "        print(\"Creating a fresh customer_orders.db...\")\n",
        "        conn = sqlite3.connect('customer_orders.db')\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS orders (\n",
        "                order_id TEXT PRIMARY KEY,\n",
        "                cust_id TEXT,\n",
        "                order_time TEXT,\n",
        "                order_status TEXT,\n",
        "                payment_status TEXT,\n",
        "                item_in_order TEXT,\n",
        "                preparing_eta TEXT,\n",
        "                prepared_time TEXT,\n",
        "                delivery_eta TEXT,\n",
        "                delivery_time TEXT\n",
        "            )\n",
        "        ''')\n",
        "        # Seed sample data for testing\n",
        "        sample_data = [\n",
        "            ('ORD001', 'CUST101', '2023-10-27 10:00:00', 'Delivered', 'Paid', 'Burger, Fries', '15m', '10:15', '30m', '10:45'),\n",
        "            ('ORD002', 'CUST102', '2023-10-27 11:00:00', 'Preparing', 'Paid', 'Pizza', '20m', None, '45m', None),\n",
        "            ('ORD003', 'CUST103', '2023-10-27 12:00:00', 'Placed', 'Pending', 'Sushi', '25m', None, '40m', None)\n",
        "        ]\n",
        "        cursor.executemany('INSERT OR REPLACE INTO orders VALUES (?,?,?,?,?,?,?,?,?,?)', sample_data)\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "    else:\n",
        "        print(\"Using existing customer_orders.db file.\")\n",
        "\n",
        "setup_database()\n",
        "db = SQLDatabase.from_uri(\"sqlite:///customer_orders.db\")\n",
        "print(\"âœ… Database is ready and connected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AWzLQ00N6j6",
        "outputId": "1fca88b6-88d4-49cd-b008-8a7e29409eb6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing customer_orders.db file.\n",
            "âœ… Database is ready and connected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.1 Load the Fine-Tuned Model ---\n",
        "# Based on your Mistral-7B Fine-Tuning project logic\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/mistral-7b-v0.3-bnb-4bit\", # Replace with your saved model path if different\n",
        "    max_seq_length = 2048,\n",
        "    load_in_4bit = True,\n",
        "    device_map=\"auto\"\n",
        "    # Removed: llm_int8_enable_fp32_cpu_offload=True\n",
        ")\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# --- 3.2 LangChain Model Wrapper ---\n",
        "class FoodHubBrain(LLM):\n",
        "    @property\n",
        "    def _llm_type(self) -> str: return \"foodhub_mistral\"\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens=200)\n",
        "        return tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True).strip()\n",
        "\n",
        "llm_brain = FoodHubBrain()\n",
        "\n",
        "# --- 3.3 Internal SQL Tool with Guardrails ---\n",
        "sql_agent_internal = create_sql_agent(llm=llm_brain, db=db, verbose=False)\n",
        "\n",
        "def secure_query_tool(query):\n",
        "    # RUBRIC: Input Guardrail to prevent misuse\n",
        "    if any(word in query.lower() for word in [\"every\", \"all\", \"dump\", \"database\", \"hack\"]):\n",
        "        return \"Access Denied: You are only authorized to query specific individual Order IDs.\"\n",
        "\n",
        "    # RUBRIC: Escalation Logic\n",
        "    if any(word in query.lower() for word in [\"resolution\", \"immediate\", \"human\", \"stuck\"]):\n",
        "        return \"I apologize for the delay in resolving your issue. I am escalating this ticket to a human support supervisor for immediate review.\"\n",
        "\n",
        "    try:\n",
        "        return sql_agent_internal.invoke({\"input\": query})[\"output\"]\n",
        "    except Exception as e:\n",
        "        return f\"I couldn't find that order. Please verify the Order ID. Error: {str(e)}\"\n",
        "\n",
        "# --- 3.4 Combine Tools and Initialize Agent ---\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Order_Lookup\",\n",
        "        func=secure_query_tool,\n",
        "        description=\"Search status, items, or ETA for a specific Order ID.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Removed: from langchain import hub # This import is causing an error\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "# Removed: from langchain.agents import AgentExecutor, create_react_agent # This import is causing an error\n",
        "\n",
        "# ReAct Prompt Template (manual definition since langchain.hub was problematic)\n",
        "react_prompt_template_str = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}\"\"\"\n",
        "prompt_template = PromptTemplate.from_template(react_prompt_template_str)\n",
        "\n",
        "# Using sql_agent_internal directly as it's already a functional agent\n",
        "# If a custom ReAct agent is strictly needed, the problematic imports for AgentExecutor and create_react_agent would need further debugging/environment restart.\n",
        "chat_agent = sql_agent_internal # Renaming for consistency with original notebook's intent for a 'chat_agent'\n",
        "\n",
        "print(\"âœ… Chat Agent initialized with Guardrails and SQL Agent.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU_KKl4WVZjJ",
        "outputId": "e574a4ae-6e96-4184-d91b-fd02066fca23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2026.1.3: Fast Mistral patching. Transformers: 4.57.6.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "âœ… Chat Agent initialized with Guardrails and SQL Agent.\n"
          ]
        }
      ]
    }
  ]
}